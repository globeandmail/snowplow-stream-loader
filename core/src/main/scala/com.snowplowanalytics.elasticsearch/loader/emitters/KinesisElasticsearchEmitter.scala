/**
 * Copyright (c) 2014-2017 Snowplow Analytics Ltd.
 * All rights reserved.
 *
 * This program is licensed to you under the Apache License Version 2.0,
 * and you may not use this file except in compliance with the Apache
 * License Version 2.0.
 * You may obtain a copy of the Apache License Version 2.0 at
 * http://www.apache.org/licenses/LICENSE-2.0.
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the Apache License Version 2.0 is distributed
 * on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
 * either express or implied.
 *
 * See the Apache License Version 2.0 for the specific language
 * governing permissions and limitations there under.
 */

package com.snowplowanalytics.elasticsearch.loader.emitters

// Amazon
import com.amazonaws.services.kinesis.connectors.interfaces.IEmitter
import com.amazonaws.services.kinesis.connectors.{KinesisConnectorConfiguration, UnmodifiableBuffer}
import com.snowplowanalytics.elasticsearch.loader.EmitterInput
import com.snowplowanalytics.elasticsearch.loader.clients.BulkSender
import com.snowplowanalytics.elasticsearch.loader.sinks.ISink
import com.snowplowanalytics.snowplow.scalatracker.Tracker

// Java
import java.io.IOException
import java.util.{List => JList}

// Joda-Time
import org.joda.time.format.DateTimeFormat
import org.joda.time.{DateTime, DateTimeZone}

// Scala
import scala.collection.JavaConversions._

// Scalaz

// Tracker

// This project

/**
 * Class to send valid records to Elasticsearch and invalid records to Kinesis
 *
 * @param configuration the KCL configuration
 * @param goodSink the configured GoodSink
 * @param badSink the configured BadSink
 * @param elasticsearchSender ES Client to use
 * @param tracker a Tracker instance
 */
class KinesisElasticsearchEmitter(
                                   configuration: KinesisConnectorConfiguration,
                                   goodSink: Option[ISink],
                                   badSink: ISink,
                                   elasticsearchSender: BulkSender,
                                   tracker: Option[Tracker] = None
) extends IEmitter[EmitterInput] {

  // An ISO valid timestamp formatter
  private val TstampFormat = DateTimeFormat.forPattern("yyyy-MM-dd'T'HH:mm:ss.SSS'Z'").withZone(DateTimeZone.UTC)

  // ElasticsearchEmitter instance
  private val elasticsearchEmitter = new ElasticsearchEmitter(elasticsearchSender, 
                                                              goodSink, 
                                                              badSink, 
                                                              configuration.BUFFER_RECORD_COUNT_LIMIT,  
                                                              configuration.BUFFER_BYTE_SIZE_LIMIT)
  /**
   * Emits good records to stdout or Elasticsearch.
   * All records which Elasticsearch rejects and all records which failed transformation
   * get sent to to stderr or Kinesis.
   *
   * @param buffer BasicMemoryBuffer containing EmitterInputs
   * @return list of inputs which failed transformation or which Elasticsearch rejected
   */
  @throws[IOException]
  override def emit(buffer: UnmodifiableBuffer[EmitterInput]): JList[EmitterInput] = {
    val records = buffer.getRecords.toList
    elasticsearchEmitter.attempEmit(records)
  }

  /**
   * Handles records rejected by the SnowplowElasticsearchTransformer or by Elasticsearch
   *
   * @param records List of failed records
   */
  override def fail(records: JList[EmitterInput]): Unit =
    elasticsearchEmitter.fail(records.toList)

  /**
   * Closes the Elasticsearch client when the KinesisConnectorRecordProcessor is shut down
   */
  override def shutdown(): Unit = elasticsearchSender.close

  /**
   * Returns an ISO valid timestamp
   *
   * @param tstamp The Timestamp to convert
   * @return the formatted Timestamp
   */
  private def getTimestamp(tstamp: Long): String = {
    val dt = new DateTime(tstamp)
    TstampFormat.print(dt)
  }
}
